{"cells":[{"cell_type":"markdown","source":["**Version History**\n","\n","VAE_v1 :- The original code \n","\n","VAE_v2 :- Updated code with test action\n","\n","VAE_v3 :- Hardtanh activation in linear layers\n","\n","VAE_v4 :- Hardtanh everywhere"],"metadata":{"id":"GjyqPJ5X5wzl"}},{"cell_type":"markdown","metadata":{"id":"SYS71vQf3PFz"},"source":["**Cloning Git repository**"]},{"cell_type":"code","source":["!git clone https://github.com/Adu3108/Binarized_VAE.git"],"metadata":{"id":"HrYam_fiHUzf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extracting the necessary code**"],"metadata":{"id":"we-uT-QE7dy-"}},{"cell_type":"code","source":["!mv /content/Binarized_VAE/First\\ VAE/Normal\\ Version/bvae_v2.py /content/ # Version 2\n","!mv /content/Binarized_VAE/First\\ VAE/Normal\\ Version/bvae_v3.py /content/ # Version 3\n","!mv /content/Binarized_VAE/First\\ VAE/Normal\\ Version/bvae_v4.py /content/ # Version 4"],"metadata":{"id":"w9fROh9_3Wq1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3hpcXGfdTZ0V"},"source":["**Install all the dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upPdK0BrbZzk"},"outputs":[],"source":["!pip install torch \n","!pip install torchvision"]},{"cell_type":"markdown","metadata":{"id":"sBB-T_VdTnpv"},"source":["**Install the dataset**"]},{"cell_type":"markdown","source":["**MNIST Dataset**"],"metadata":{"id":"Ai300DPA7pmZ"}},{"cell_type":"code","source":["!mv /content/Binarized_VAE/Datasets/MNIST\\ Dataset\\ JPG\\ format.zip /content/"],"metadata":{"id":"mgxZctAb4NDj","executionInfo":{"status":"ok","timestamp":1656177634117,"user_tz":-330,"elapsed":418,"user":{"displayName":"Advait Padhye","userId":"01091457241827793857"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOfiO-zBTtet"},"source":["**Preprocessing of MNIST Dataset**\n","\n","There will be 2 directories :- \n","1.   Training\n","2.   Testing\n","\n","Each directory consists of 10 classes named 0,1,2,...,9\n","\n","Each class contains 10 images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PMWSrTg6TUZO"},"outputs":[],"source":["import os\n","\n","os.rename('/content/MNIST Dataset JPG format.zip','MNIST.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx9O9luEg4PX"},"outputs":[],"source":["!jar xvf /content/MNIST.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlI_cq3TTjZ2"},"outputs":[],"source":["os.rename('/content/MNIST Dataset JPG format', 'MNIST')\n","os.rename('/content/MNIST/MNIST - JPG - training','/content/MNIST/Training')\n","os.rename('/content/MNIST/MNIST - JPG - testing', '/content/MNIST/Testing')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muA0jzt3UJ3J"},"outputs":[],"source":["os.chdir('/content/MNIST/Training')\n","arr = os.listdir()\n","for i in arr:\n","  tmp = os.path.join('/content/MNIST/Training',i)\n","  os.chdir(tmp)\n","  rem = os.listdir()[10:]\n","  for j in rem:\n","    os.remove(j)\n","os.chdir('/content/MNIST/Testing')\n","arr = os.listdir()\n","for i in arr:\n","  tmp = os.path.join('/content/MNIST/Testing',i)\n","  os.chdir(tmp)\n","  rem = os.listdir()[10:]\n","  for j in rem:\n","    os.remove(j)\n","os.chdir('/content')"]},{"cell_type":"markdown","source":["**Caltech-101 Dataset**"],"metadata":{"id":"0GFQdAQi-yBL"}},{"cell_type":"code","source":["!mv /content/Binarized_VAE/Datasets/Caltech-101 /content/"],"metadata":{"id":"N77IjsOK-17W","executionInfo":{"status":"ok","timestamp":1656177811915,"user_tz":-330,"elapsed":449,"user":{"displayName":"Advait Padhye","userId":"01091457241827793857"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Creating Training, Validation, Testing dataset**"],"metadata":{"id":"-q_2R8DyytZI"}},{"cell_type":"code","source":["import os\n","\n","os.mkdir('/content/Dataset')\n","os.mkdir('/content/Dataset/Training')\n","os.mkdir('/content/Dataset/Testing')\n","os.mkdir('/content/Dataset/Validation')\n","os.chdir(\"/content/Caltech-101/\")\n","l = os.listdir()\n","os.chdir('/content/Dataset/Training')\n","for i in l:\n","  path = os.path.join('/content/Dataset/Training',i)\n","  os.mkdir(path)\n","os.chdir('/content/Dataset/Validation')\n","for i in l:\n","  path = os.path.join('/content/Dataset/Validation',i)\n","  os.mkdir(path)  \n","os.chdir('/content/Dataset/Testing')\n","for i in l:\n","  path = os.path.join('/content/Dataset/Testing',i)\n","  os.mkdir(path)"],"metadata":{"id":"kpilmK2rHU0G","executionInfo":{"status":"ok","timestamp":1656177813872,"user_tz":-330,"elapsed":4,"user":{"displayName":"Advait Padhye","userId":"01091457241827793857"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Es2lP6X46EB6"},"source":["**Preprocessing of Caltech-101 Dataset**\n","\n","There will be 3 directories :- \n","1.   Training\n","2.   Validation\n","1.   Testing\n","\n","Each directory consists of 102 classes\n","\n","Each class contains 10 images"]},{"cell_type":"code","source":["for i in l:\n","  path = os.path.join('/content/Caltech-101/',i)\n","  os.chdir(path)\n","  training = os.listdir()[:10]\n","  validation = os.listdir()[10:20]\n","  testing = os.listdir()[20:30]\n","  rem = os.listdir()[30:]\n","  for j in training:\n","    original_path = os.path.join(path,j)\n","    val_path = os.path.join('/content/Dataset/Training',i)\n","    val_path = os.path.join(val_path,j)\n","    os.replace(original_path,val_path)\n","  for j in validation:\n","    original_path = os.path.join(path,j)\n","    val_path = os.path.join('/content/Dataset/Validation',i)\n","    val_path = os.path.join(val_path,j)\n","    os.replace(original_path,val_path)\n","  for j in testing:\n","    original_path = os.path.join(path,j)\n","    val_path = os.path.join('/content/Dataset/Testing',i)\n","    val_path = os.path.join(val_path,j)\n","    os.replace(original_path,val_path)\n","  for j in rem:\n","    os.remove(j)\n","  os.chdir('/content')"],"metadata":{"id":"DwbOy8ek_4FQ","executionInfo":{"status":"ok","timestamp":1656177816687,"user_tz":-330,"elapsed":403,"user":{"displayName":"Advait Padhye","userId":"01091457241827793857"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mFkdFHA7Tynu"},"source":["**Training**"]},{"cell_type":"markdown","source":["**MNIST Dataset**"],"metadata":{"id":"zk7z8vYd4t-Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QF1CxlStcIPi"},"outputs":[],"source":["#!python bvae_v2.py train --grayscale --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/MNIST/Training # Version 2\n","#!python bvae_v3.py train --grayscale --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/MNIST/Training # Version 3\n","!python bvae_v4.py train --grayscale --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/MNIST/Training # Version 4"]},{"cell_type":"markdown","source":["**Caltech-101 Dataset**"],"metadata":{"id":"hMD96liW4wax"}},{"cell_type":"code","source":["#!python bvae_v2.py train --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/Dataset/Training # Version 2\n","#!python bvae_v3.py train --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/Dataset/Training # Version 3\n","!python bvae_v4.py train --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/Dataset/Training # Version 4"],"metadata":{"id":"ebbnJxTm4zH4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_7j___DT3kh"},"source":["**Preprocessing of Weights file**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4A8iJLEHZ_Xj"},"outputs":[],"source":["for root, dirs, files in os.walk('/content'):\n","    for file in files:\n","        if file.endswith('.pt'):\n","            weights = root+'/'+str(file)\n","os.rename(weights, '/content/weights.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q7ETul6g59sT"},"outputs":[],"source":["%matplotlib inline\n","%matplotlib notebook"]},{"cell_type":"markdown","metadata":{"id":"IEtFI1LWWgMG"},"source":["**Fixing the final directory structure**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BGUbIOZrIGnN"},"outputs":[],"source":["!mkdir Results\n","!mkdir /content/Results/Input\n","!mkdir /content/Results/Reconstructed"]},{"cell_type":"markdown","metadata":{"id":"2rhDeA4NWpIk"},"source":["**Reconstruction**"]},{"cell_type":"markdown","source":["**MNIST Dataset**"],"metadata":{"id":"njxPBgMK5GWL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YgZjtLwoZRUS"},"outputs":[],"source":["# !python bvae_v2.py test --grayscale --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/MNIST/Testing --weights /content/weights.pt # Version 2\n","# !python bvae_v3.py test --grayscale --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/MNIST/Testing --weights /content/weights.pt # Version 3\n","!python bvae_v4.py test --grayscale --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/MNIST/Testing --weights /content/weights.pt # Version 4"]},{"cell_type":"markdown","source":["**Caltech-101 Dataset**"],"metadata":{"id":"k8QmRQOp5JPk"}},{"cell_type":"code","source":["# !python bvae_v2.py test --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/Dataset/Testing --weights /content/weights.pt # Version 2\n","# !python bvae_v3.py test --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/Dataset/Testing --weights /content/weights.pt # Version 3\n","!python bvae_v4.py test --beta 1 --n_latent 30 --dimensions 28x28 --dataset /content/Dataset/Testing --weights /content/weights.pt # Version 4"],"metadata":{"id":"J0BwgqVN5OBn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_m2j1JOhWsuZ"},"source":["**Comparison between original image and reconstructed image**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEb0K5SsN6HX"},"outputs":[],"source":["os.chdir('/content/Results/Input')\n","inputs = os.listdir()\n","inputs.sort()\n","inputs = inputs[1:]\n","os.chdir('/content/Results/Reconstructed')\n","outputs = os.listdir()\n","outputs.sort()\n","outputs = outputs[1:]\n","os.chdir('/content')"]},{"cell_type":"code","source":["!mv /content/Binarized_VAE/Datasets/Screenshot\\ 2022-06-15\\ at\\ 4.58.08\\ PM.png /content/\n","os.rename('/content/Screenshot 2022-06-15 at 4.58.08 PM.png','/content/white.png')"],"metadata":{"id":"wqBys5LL1dEM","executionInfo":{"status":"ok","timestamp":1656177970372,"user_tz":-330,"elapsed":397,"user":{"displayName":"Advait Padhye","userId":"01091457241827793857"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcRoemVHAbil"},"outputs":[],"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","white = cv2.imread('white.png')\n","errorfile = open(\"/content/Results/errors.txt\",\"r+\")\n","errors = errorfile.readlines()\n","for i in range(len(inputs)):\n","  input_path = os.path.join('/content/Results/Input',inputs[i])\n","  output_path = os.path.join('/content/Results/Reconstructed',outputs[i])\n","  img1 = cv2.imread(input_path)\n","  img2 = cv2.imread(output_path)\n","  scale_percent = 500 # percent of original size\n","  width1 = int(img1.shape[1] * scale_percent / 100)\n","  height1 = int(img1.shape[0] * scale_percent / 100)\n","  dim1 = (width1, height1)\n","  width2 = int(img2.shape[1] * scale_percent / 100)\n","  height2 = int(img2.shape[0] * scale_percent / 100)\n","  dim2 = (width2, height2)\n","\n","  resized1 = cv2.resize(img1, dim1, interpolation = cv2.INTER_AREA)\n","  resized2 = cv2.resize(img2, dim2, interpolation = cv2.INTER_AREA)\n","\n","  im_v = cv2.hconcat([resized1, white, resized2])\n","\n","  cv2_imshow(im_v)\n","  print(errors[i])"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"BVAE.ipynb","provenance":[],"authorship_tag":"ABX9TyN0B5FkMvcVuXPPO8AGGkkY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}