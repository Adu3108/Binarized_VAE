{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary_Second_VAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSq54KW-TVDa"
      },
      "source": [
        "**Cloning Git repository**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Adu3108/Binarized_VAE.git"
      ],
      "metadata": {
        "id": "HrYam_fiHUzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46caa2d3-2387-49ec-c29c-93282d6ad4a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Binarized_VAE'...\n",
            "remote: Enumerating objects: 9277, done.\u001b[K\n",
            "remote: Counting objects: 100% (3181/3181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3171/3171), done.\u001b[K\n",
            "remote: Total 9277 (delta 8), reused 3180 (delta 8), pack-reused 6096\u001b[K\n",
            "Receiving objects: 100% (9277/9277), 147.00 MiB | 16.63 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "Checking out files: 100% (9157/9157), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting the necessary code**"
      ],
      "metadata": {
        "id": "we-uT-QE7dy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Binarized_VAE/Second\\ VAE/Normal\\ Version/vae.py /content/"
      ],
      "metadata": {
        "id": "rTHg37uN9Aa_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hpcXGfdTZ0V"
      },
      "source": [
        "**Install all the dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upPdK0BrbZzk",
        "outputId": "dc747957-c84b-4f0d-fb0c-2aae22bf9150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0+cu113)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch \n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dataset**"
      ],
      "metadata": {
        "id": "AD9PBifU98d-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MNIST Dataset**"
      ],
      "metadata": {
        "id": "oTBsxcQD-A-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Binarized_VAE/Datasets/MNIST\\ Dataset\\ JPG\\ format.zip /content/ "
      ],
      "metadata": {
        "id": "Bon3c2chHgtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOfiO-zBTtet"
      },
      "source": [
        "**Preprocessing of Dataset**\n",
        "\n",
        "There will be 2 directories :- \n",
        "1.   Training\n",
        "2.   Testing\n",
        "\n",
        "Each directory consists of 10 classes named 0,1,2,...,9\n",
        "\n",
        "Each class contains 10 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMWSrTg6TUZO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.rename('/content/MNIST Dataset JPG format.zip','MNIST.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx9O9luEg4PX"
      },
      "outputs": [],
      "source": [
        "!jar xvf /content/MNIST.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlI_cq3TTjZ2"
      },
      "outputs": [],
      "source": [
        "os.rename('/content/MNIST Dataset JPG format', 'MNIST')\n",
        "os.rename('/content/MNIST/MNIST - JPG - training','/content/MNIST/Training')\n",
        "os.rename('/content/MNIST/MNIST - JPG - testing', '/content/MNIST/Testing')\n",
        "os.mkdir(\"/content/MNIST/Validation\")\n",
        "for i in range(10):\n",
        "  path = os.path.join('/content/MNIST/Validation',str(i))\n",
        "  os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muA0jzt3UJ3J"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/MNIST/Training')\n",
        "arr = os.listdir()\n",
        "for i in arr:\n",
        "  tmp = os.path.join('/content/MNIST/Training',i)\n",
        "  os.chdir(tmp)\n",
        "  val = os.listdir()[10:20]\n",
        "  rem = os.listdir()[20:]\n",
        "  for j in val:\n",
        "    original_path = os.path.join(tmp,j)\n",
        "    val_path = os.path.join('/content/MNIST/Validation',i)\n",
        "    val_path = os.path.join(val_path,j)\n",
        "    os.replace(original_path,val_path)\n",
        "  for j in rem:\n",
        "    os.remove(j)\n",
        "os.chdir('/content/MNIST/Testing')\n",
        "arr = os.listdir()\n",
        "for i in arr:\n",
        "  tmp = os.path.join('/content/MNIST/Testing',i)\n",
        "  os.chdir(tmp)\n",
        "  rem = os.listdir()[10:]\n",
        "  for j in rem:\n",
        "    os.remove(j)\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Caltech-101 Dataset**"
      ],
      "metadata": {
        "id": "0GFQdAQi-yBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Binarized_VAE/Datasets/Caltech-101 /content/"
      ],
      "metadata": {
        "id": "N77IjsOK-17W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Training, Validation, Testing dataset**"
      ],
      "metadata": {
        "id": "-q_2R8DyytZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.mkdir('/content/Dataset')\n",
        "os.mkdir('/content/Dataset/Training')\n",
        "os.mkdir('/content/Dataset/Testing')\n",
        "os.mkdir('/content/Dataset/Validation')\n",
        "os.chdir(\"/content/Caltech-101/\")\n",
        "l = os.listdir()\n",
        "os.chdir('/content/Dataset/Training')\n",
        "for i in l:\n",
        "  path = os.path.join('/content/Dataset/Training',i)\n",
        "  os.mkdir(path)\n",
        "os.chdir('/content/Dataset/Validation')\n",
        "for i in l:\n",
        "  path = os.path.join('/content/Dataset/Validation',i)\n",
        "  os.mkdir(path)  \n",
        "os.chdir('/content/Dataset/Testing')\n",
        "for i in l:\n",
        "  path = os.path.join('/content/Dataset/Testing',i)\n",
        "  os.mkdir(path)"
      ],
      "metadata": {
        "id": "kpilmK2rHU0G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in l:\n",
        "  path = os.path.join('/content/Caltech-101/',i)\n",
        "  os.chdir(path)\n",
        "  training = os.listdir()[:10]\n",
        "  validation = os.listdir()[10:20]\n",
        "  testing = os.listdir()[20:30]\n",
        "  rem = os.listdir()[30:]\n",
        "  for j in training:\n",
        "    original_path = os.path.join(path,j)\n",
        "    val_path = os.path.join('/content/Dataset/Training',i)\n",
        "    val_path = os.path.join(val_path,j)\n",
        "    os.replace(original_path,val_path)\n",
        "  for j in validation:\n",
        "    original_path = os.path.join(path,j)\n",
        "    val_path = os.path.join('/content/Dataset/Validation',i)\n",
        "    val_path = os.path.join(val_path,j)\n",
        "    os.replace(original_path,val_path)\n",
        "  for j in testing:\n",
        "    original_path = os.path.join(path,j)\n",
        "    val_path = os.path.join('/content/Dataset/Testing',i)\n",
        "    val_path = os.path.join(val_path,j)\n",
        "    os.replace(original_path,val_path)\n",
        "  for j in rem:\n",
        "    os.remove(j)\n",
        "  os.chdir('/content')"
      ],
      "metadata": {
        "id": "DwbOy8ek_4FQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "CgFmSSjCy9L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
        "!python binary_vae_v1.py train --epochs 100 --batch 1 --n_latent 30 --dimensions 120x160 --train_set /content/Dataset/Training --validation_set /content/Dataset/Validation --weights /content/weights.pt"
      ],
      "metadata": {
        "id": "NPtmLA5my79j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Q7ETul6g59sT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEtFI1LWWgMG"
      },
      "source": [
        "**Fixing the final directory structure**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BGUbIOZrIGnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5725008-889a-4a13-b2dc-70228883a964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘Results’: File exists\n",
            "mkdir: cannot create directory ‘/content/Results/Input’: File exists\n",
            "mkdir: cannot create directory ‘/content/Results/Reconstructed’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir Results\n",
        "!mkdir /content/Results/Input\n",
        "!mkdir /content/Results/Reconstructed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python vae.py calibrate --batch 1 --n_latent 30 --dimensions 120x160 --cal_set /content/Dataset/Testing --weights weights.pt"
      ],
      "metadata": {
        "id": "R2vblYUL3sYu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m2j1JOhWsuZ"
      },
      "source": [
        "**Comparison between original image and reconstructed image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEb0K5SsN6HX"
      },
      "outputs": [],
      "source": [
        "path = '/content/Results/Input'\n",
        "os.chdir(path)\n",
        "inputs = os.listdir()\n",
        "for item in inputs:\n",
        "    if not item.endswith(\".png\"):\n",
        "        os.remove(os.path.join(path, item))\n",
        "inputs.sort()\n",
        "path = '/content/Results/Reconstructed'\n",
        "os.chdir(path)\n",
        "outputs = os.listdir()\n",
        "for item in outputs:\n",
        "    if not item.endswith(\".png\"):\n",
        "        os.remove(os.path.join(path, item))\n",
        "outputs.sort()\n",
        "os.chdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Binarized_VAE/Datasets/Screenshot\\ 2022-06-15\\ at\\ 4.58.08\\ PM.png /content/\n",
        "os.rename('/content/Screenshot 2022-06-15 at 4.58.08 PM.png','/content/white.png')"
      ],
      "metadata": {
        "id": "wqBys5LL1dEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf_NPabeRQD9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "white = cv2.imread('white.png')\n",
        "resized_white = cv2.resize(white, (160,120), interpolation = cv2.INTER_AREA)\n",
        "with open('/content/KL_Losses.json') as kl_json_file:\n",
        "    kl_data = json.load(kl_json_file)\n",
        "with open('/content/MSE_Losses.json') as mse_json_file:\n",
        "    mse_data = json.load(mse_json_file)\n",
        "for i in range(len(inputs)):\n",
        "  input_path = os.path.join('/content/Results/Input',inputs[i])\n",
        "  output_path = os.path.join('/content/Results/Reconstructed',outputs[i])\n",
        "  img1 = cv2.imread(input_path)\n",
        "  img2 = cv2.imread(output_path)\n",
        "  #img = Image.fromarray(img2.astype('uint8'), 'RGB')\n",
        "  #img.save(f'/content/Temp/{i}.jpg') \n",
        "  # scale_percent = 500 # percent of original size\n",
        "  # width1 = int(img1.shape[1] * scale_percent / 100)\n",
        "  # height1 = int(img1.shape[0] * scale_percent / 100)\n",
        "  # dim1 = (width1, height1)\n",
        "  # width2 = int(img2.shape[1] * scale_percent / 100)\n",
        "  # height2 = int(img2.shape[0] * scale_percent / 100)\n",
        "  # dim2 = (width2, height2)\n",
        "\n",
        "  # resized1 = cv2.resize(img1, dim1, interpolation = cv2.INTER_AREA)\n",
        "  # resized2 = cv2.resize(img2, dim2, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "  im_v = cv2.hconcat([img1, resized_white, img2])\n",
        "\n",
        "  cv2_imshow(im_v)\n",
        "  print(\"KL Loss : \" + str(float(kl_data[inputs[i][:-4]][1:-1])))\n",
        "  print(\"MSE Loss : \" + str(float(mse_data[f'{int(inputs[i][:-4])}'][1:-1])))\n",
        "  print()"
      ]
    }
  ]
}